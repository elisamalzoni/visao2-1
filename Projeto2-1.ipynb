{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeto 2-1 Visão Computacional\n",
    "#### Elisa Malzoni\n",
    "\n",
    "Esse projeto foi feito em etapas conforme as rúbricas e cada etapa pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aula 09 - Good features to Track\n",
    "\n",
    "Estabilização parcial com os programas da aula 09."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura = cv2.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "# Parametriza a funcao do OpenCV\n",
    "dt_params = dict( maxCorners = 100,\n",
    "           qualityLevel = 0.3,\n",
    "           minDistance = 7,\n",
    "           blockSize = 7 )\n",
    "\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Parametriza o Lucas-Kanade\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "ret, previous = captura.read()\n",
    "\n",
    "previous_gray = cv2.cvtColor(previous, cv2.COLOR_RGB2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(previous_gray, mask = None, **dt_params)\n",
    "mask = np.zeros_like(previous)\n",
    "\n",
    "fomv = [0,0] # vetor do fluxo ótico médio acumulado \n",
    "\n",
    "while(1):\n",
    "    \n",
    "    ret, actual = captura.read()\n",
    "    actual_gray = cv2.cvtColor(actual, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calcula Fluxo Otico\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(previous_gray, actual_gray, p0, None, **lk_params)\n",
    "        \n",
    "    # Seleciona somente os melhores pontos\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "       \n",
    "\n",
    "    # Desenha as trilhas para cada ponto em p1 e p0\n",
    "    for i,(new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), [0,0,255], 2)\n",
    "        actual = cv2.circle(actual,(a,b),5,color[i].tolist(),-1)\n",
    "    \n",
    "\n",
    "    # Calcula fluxo otico medio\n",
    "    sub = np.subtract(good_new, good_old)\n",
    "    fom = np.mean(sub, axis=0) \n",
    "    fom = (-1)*fom\n",
    "    fomv += fom\n",
    "    \n",
    "    frame = cv2.add(actual, mask)\n",
    "    framebw = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    rows, cols = framebw.shape\n",
    "    \n",
    "    # componentes do vertor inverso do fluxo ótico\n",
    "    tx = (int(fomv[0]))\n",
    "    ty = (int(fomv[1]))\n",
    "    \n",
    "    # Matriz de translação\n",
    "    M = np.float32([[1,0,tx],\n",
    "                    [0,1,ty]])\n",
    "    \n",
    "    # frame transladado\n",
    "    framet = cv2.warpAffine(frame, M,(cols,rows))\n",
    "    \n",
    "    # mostra frame transladado\n",
    "    cv2.imshow(\"Video\", framet)\n",
    "    \n",
    "    # Atualiza a imagem anterior com a imagem atual e copia os pontos.\n",
    "    previous_gray = actual_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    \n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Optical flow\n",
    "\n",
    "Dense Optical Flow de uma janela no centro da imagem, quadrada com lado $l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura = cv2.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "ret, previous = captura.read() # captura imagem da câmera\n",
    "previous = cv2.flip(previous,1) # flipa horizontalmente a imagem\n",
    "\n",
    "previous_gray = cv2.cvtColor(previous, cv2.COLOR_RGB2GRAY) #converte a imagem capturada para escala de cinza\n",
    "\n",
    "# dimensões do frame\n",
    "w = previous.shape[0]\n",
    "h = previous.shape[1]\n",
    "\n",
    "fomv = [0,0] #vetor do fluxo ótico\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    ret, actual = captura.read()\n",
    "    actual = cv2.flip(actual,1)\n",
    "    actual_gray = cv2.cvtColor(actual, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calcula Fluxo Otico\n",
    "    l = 120 # tamanho do lado da janela no centro, quadrada, onde o fluxo ótico será calculado\n",
    "    previous_gray_center = previous_gray[int((w/2)-(l/2)+1):int((w/2)+(l/2)+1), int((h/2)-(l/2)+1):int((h/2)+(l/2)+1)]#slicing para pegar o centro da imagem\n",
    "    actual_gray_center = actual_gray[int((w/2)-(l/2)+1):int((w/2)+(l/2)+1), int((h/2)-(l/2)+1):int((h/2)+(l/2)+1)]    \n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_gray_center, actual_gray_center,None, 0.5, 3, 15, 3, 5, 1.2, 0)       \n",
    "    \n",
    "    # Calcula fluxo ótico médio em x e em y\n",
    "    xmean = (np.mean(flow[:,:,0]))\n",
    "    ymean = (np.mean(flow[:,:,1]))\n",
    "    fom = np.array([xmean, ymean])\n",
    "    fom *= -1\n",
    "    fomv += fom # acumula o fluxo ótico médio\n",
    "         \n",
    "    # converte o frame atual para escala de cinza\n",
    "    framebw = cv2.cvtColor(actual, cv2.COLOR_RGB2GRAY) \n",
    "    # dimensões do frame convertido\n",
    "    rows, cols = framebw.shape \n",
    "    \n",
    "    # componentes do vertor inverso do fluxo ótico\n",
    "    tx = (int(fomv[0]))\n",
    "    ty = (int(fomv[1]))\n",
    "    \n",
    "    # matriz de translação\n",
    "    M = np.float32([[1,0,tx],\n",
    "                    [0,1,ty]])\n",
    "\n",
    "    # translada o frame\n",
    "    framet = cv2.warpAffine(actual, M,(cols,rows))\n",
    "\n",
    "    # mostra o frame\n",
    "    cv2.imshow(\"Video\", framet)\n",
    "    \n",
    "    # mostra a janela central onde o fluxo está sendo calculado\n",
    "#     cv2.imshow(\"centro\", actual_gray_center)\n",
    "    \n",
    "    # Atualiza a imagem anterior com a imagem atual e copia os pontos.\n",
    "    previous_gray = actual_gray\n",
    "    \n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complementando a célula acima porém com compensação das faixas pretas nos cantos da imagem com algum limite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura = cv2.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "ret, previous = captura.read()\n",
    "previous = cv2.flip(previous,1)\n",
    "\n",
    "previous_gray = cv2.cvtColor(previous, cv2.COLOR_RGB2GRAY)\n",
    "hsv = np.zeros_like(previous)\n",
    "\n",
    "# dimensões do frame\n",
    "w = previous.shape[0]\n",
    "h = previous.shape[1]\n",
    "\n",
    "ratio = w/h\n",
    "\n",
    "fomv = [0,0] #vetor do fluxo ótico acumulado\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    ret, actual = captura.read()\n",
    "    actual = cv2.flip(actual,1)\n",
    "    actual_gray = cv2.cvtColor(actual, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calcula Fluxo Otico\n",
    "    l = 120 # tamanho do lado da janela no centro, quadrada, onde o fluxo será calculado\n",
    "    previous_gray_center = previous_gray[int((w/2)-(l/2)+1):int((w/2)+(l/2)+1), int((h/2)-(l/2)+1):int((h/2)+(l/2)+1)]#slicing para pegar o centro da imagem\n",
    "    actual_gray_center = actual_gray[int((w/2)-(l/2)+1):int((w/2)+(l/2)+1), int((h/2)-(l/2)+1):int((h/2)+(l/2)+1)]\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_gray_center, actual_gray_center,None, 0.5, 3, 15, 3, 5, 1.2, 0)       \n",
    "    \n",
    "    # Calcula fluxo ótico médio em x e em y\n",
    "    xmean = (np.mean(flow[:,:,0]))\n",
    "    ymean = (np.mean(flow[:,:,1]))\n",
    "    fom = np.array([xmean, ymean])\n",
    "    # inverte vetor do Fluxo ótico\n",
    "    fom *= -1\n",
    "    fomv += fom\n",
    "         \n",
    "    \n",
    "    framebw = cv2.cvtColor(actual, cv2.COLOR_RGB2GRAY)\n",
    "    rows, cols = framebw.shape\n",
    "    \n",
    "    # componentes do inverso do fluxo ótico\n",
    "    tx = (int(fomv[0]))\n",
    "    ty = (int(fomv[1]))\n",
    "    \n",
    "    # Matriz de Translação\n",
    "    M = np.float32([[1,0,tx],\n",
    "                    [0,1,ty]])\n",
    "    \n",
    "    #frame transladado\n",
    "    framet = cv2.warpAffine(actual, M,(cols,rows))\n",
    "\n",
    "    #scaling\n",
    "    #dimensões imagem cortada\n",
    "    wt = w - abs(tx)\n",
    "    ht = h - abs(ty)\n",
    "    \n",
    "    # Proporção da imagem cortada\n",
    "    ratio_cut = wt/ht\n",
    "    \n",
    "    # Assumir que as dimensões da imagem permanecerão as mesmas\n",
    "    wtc = wt\n",
    "    htc = ht\n",
    "    \n",
    "    if ratio > ratio_cut:\n",
    "        #corta em y\n",
    "        htc = int((h*wt)/w)\n",
    "\n",
    "    else:\n",
    "        #corta em x\n",
    "        wtc = int((ht*w)/h)\n",
    "    \n",
    "    # Cálculo da origem após cortar a imagem\n",
    "    if tx < 0:\n",
    "        origin_x_cut = w - wtc + tx\n",
    "    else:\n",
    "        origin_x_cut = w - wtc\n",
    "\n",
    "    if ty < 0:\n",
    "        origin_y_cut = h - htc + ty\n",
    "    else:\n",
    "        origin_y_cut = h - htc\n",
    "        \n",
    "    new_ratio_cut = wtc/htc\n",
    "    \n",
    "    \n",
    "    # slicing da imagem com o mesmo ratio da câmera\n",
    "    framet_cut  = framet[origin_x_cut:(origin_x_cut+wtc), origin_y_cut:(origin_y_cut + htc)]\n",
    "\n",
    "    \n",
    "    # Matriz de translação para trazer a imagem de volta ao centro\n",
    "    M2 = np.float32([[1,0,int(-origin_x_cut/2)],\n",
    "                    [0,1,int(-origin_y_cut/2)]])\n",
    "    \n",
    "    rows2, cols2, a = framet_cut.shape\n",
    "    \n",
    "    # Frame transladado da imagem cortada\n",
    "    framet_cut = cv2.warpAffine(actual, M2,(cols2,rows2))\n",
    "\n",
    "    # redimensionamento do frame acima\n",
    "    frame_ok = cv2.resize(framet_cut,(h,w), interpolation = cv2.INTER_CUBIC)\n",
    "            \n",
    "    # mostra frame redimensionado    \n",
    "    cv2.imshow(\"Estabilizado\", frame_ok)\n",
    "\n",
    "    # mostra frame original sem tratamentos\n",
    "#     cv2.imshow(\"a\", actual) \n",
    "\n",
    "    # mostra a janela central onde o fluxo está sendo calculado\n",
    "#     cv2.imshow(\"centro\", actual_gray_center)\n",
    "    \n",
    "    # Atualiza a imagem anterior com a imagem atual e copia os pontos.\n",
    "    previous_gray = actual_gray\n",
    "        \n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
