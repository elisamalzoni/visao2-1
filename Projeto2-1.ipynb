{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeto 2-1 Visão Computacional\n",
    "Elisa Malzoni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aula 09 - Good features to Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura = cv2.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "# Parametriza a funcao do OpenCV\n",
    "dt_params = dict( maxCorners = 100,\n",
    "           qualityLevel = 0.3,\n",
    "           minDistance = 7,\n",
    "           blockSize = 7 )\n",
    "\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Parametriza o Lucas-Kanade\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "ret, previous = captura.read()\n",
    "\n",
    "previous_gray = cv2.cvtColor(previous, cv2.COLOR_RGB2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(previous_gray, mask = None, **dt_params)\n",
    "mask = np.zeros_like(previous)\n",
    "\n",
    "fomv = 0\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    ret, actual = captura.read()\n",
    "    actual_gray = cv2.cvtColor(actual, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calcula Fluxo Otico\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(previous_gray, actual_gray, p0, None, **lk_params)\n",
    "        \n",
    "    # Seleciona somente os melhores pontos\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "       \n",
    "\n",
    "    # Desenha as trilhas para cada ponto em p1 e p0\n",
    "    for i,(new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), [0,0,255], 2)\n",
    "        actual = cv2.circle(actual,(a,b),5,color[i].tolist(),-1)\n",
    "    \n",
    "\n",
    "    # Calcula fluxo otico medio\n",
    "    sub = np.subtract(good_new, good_old)\n",
    "    fom = np.mean(sub, axis=0) \n",
    "    fom = (-1)*fom\n",
    "    fomv += fom\n",
    "#     print(fomv)\n",
    "    \n",
    "    frame = cv2.add(actual, mask)\n",
    "    framebw = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    rows, cols = framebw.shape\n",
    "    \n",
    "    tx = (int(fomv[0]))\n",
    "    ty = (int(fomv[1]))\n",
    "    \n",
    "    M = np.float32([[1,0,tx],\n",
    "                    [0,1,ty]])\n",
    "    \n",
    "    framet = cv2.warpAffine(frame, M,(cols,rows))\n",
    "    \n",
    "    cv2.imshow(\"Video\", framet)\n",
    "    \n",
    "    # Atualiza a imagem anterior com a imagem atual e copia os pontos.\n",
    "    previous_gray = actual_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    \n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "captura = cv2.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "ret, previous = captura.read()\n",
    "previous = cv2.flip(previous,1)\n",
    "\n",
    "previous_gray = cv2.cvtColor(previous, cv2.COLOR_RGB2GRAY)\n",
    "hsv = np.zeros_like(previous)\n",
    "\n",
    "w = previous.shape[0]\n",
    "h = previous.shape[1]\n",
    "ratio = w/h\n",
    "\n",
    "fomv = 0\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    ret, actual = captura.read()\n",
    "    actual = cv2.flip(actual,1)\n",
    "    actual_gray = cv2.cvtColor(actual, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calcula Fluxo Otico\n",
    "    l = 120 # tamanho do lado da janela no centro, quadrada\n",
    "    previous_gray_center = previous_gray[int((actual.shape[0]/2)-(l/2)+1):int((actual.shape[0]/2)+(l/2)+1), int((actual.shape[1]/2)-(l/2)+1):int((actual.shape[1]/2)+(l/2)+1)]#slicing para pegar o centro da imagem\n",
    "    actual_gray_center = actual_gray[int((actual.shape[0]/2)-(l/2)+1):int((actual.shape[0]/2)+(l/2)+1), int((actual.shape[1]/2)-(l/2)+1):int((actual.shape[1]/2)+(l/2)+1)]\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_gray_center, actual_gray_center,None, 0.5, 3, 15, 3, 5, 1.2, 0)       \n",
    "    \n",
    "    xmean = (np.mean(flow[:,:,0]))\n",
    "    ymean = (np.mean(flow[:,:,1]))\n",
    "    fom = np.array([xmean, ymean])\n",
    "    fom *= -1\n",
    "    fomv += fom\n",
    "         \n",
    "    \n",
    "    framebw = cv2.cvtColor(actual, cv2.COLOR_RGB2GRAY)\n",
    "    rows, cols = framebw.shape\n",
    "    \n",
    "    tx = (int(fomv[0]))\n",
    "    ty = (int(fomv[1]))\n",
    "    \n",
    "    M = np.float32([[1,0,tx],\n",
    "                    [0,1,ty]])\n",
    "    \n",
    "    framet = cv2.warpAffine(actual, M,(cols,rows))\n",
    "\n",
    "    #scaling\n",
    "    #dimensoes imagem cortada\n",
    "    wt = w - abs(tx)\n",
    "    ht = h - abs(ty)\n",
    "    \n",
    "    ratio_cut = wt/ht\n",
    "    \n",
    "    x_cut = 0\n",
    "    y_cut = 0\n",
    "    \n",
    "    wtc = wt\n",
    "    htc = ht\n",
    "    \n",
    "    if ratio > ratio_cut:\n",
    "        #corta em y\n",
    "        htc = int((h*wt)/w)\n",
    "        y_cut = h - htc# - ty\n",
    "    else:\n",
    "        #corta em x\n",
    "        wtc = int((ht*w)/h)\n",
    "        x_cut = w - wtc# - tx\n",
    "        \n",
    "    new_ratio_cut = wtc/htc\n",
    "    \n",
    "    origin_x_cut = w - wtc - abs(tx) #tx - x_cut\n",
    "    origin_y_cut = h - htc - abs(ty) #ty - y_cut\n",
    "    \n",
    "#     print(new_ratio_cut, ratio, tx, ty)\n",
    "    framet_cut  = framet[origin_x_cut:(origin_x_cut + wtc), origin_y_cut:(origin_y_cut + htc)]\n",
    "    \n",
    "    \n",
    "    M2 = np.float32([[1,0,int(origin_x_cut/2)],\n",
    "                    [0,1,int(origin_y_cut/2)]])\n",
    "    \n",
    "    rows2, cols2, a = framet_cut.shape\n",
    "    framet_cut = cv2.warpAffine(actual, M2,(cols2,rows2))\n",
    "\n",
    "    frame_ok = cv2.resize(framet_cut,(h,w), interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "#     txty = (\"x\" + str(tx) + \"y\" + str(ty))\n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     cv2.putText(framet,txty,(10,400), font, 1,(255,0,0),2,cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"Video\", frame_ok)\n",
    "#     cv2.imshow(\"centro\", actual_gray_center)\n",
    "    \n",
    "    # Atualiza a imagem anterior com a imagem atual e copia os pontos.\n",
    "    previous_gray = actual_gray\n",
    "        \n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
